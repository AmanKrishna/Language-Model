{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "caf4804f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "from posixpath import join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "3e7c71bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.10.1\n"
     ]
    }
   ],
   "source": [
    "print(\"Tensorflow version:\",tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8693f74b",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "71178404",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = tf.keras.utils.get_file(\n",
    "    fname='shakespeare.txt', \n",
    "    origin='https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt',\n",
    "    cache_dir=\".\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4f951f",
   "metadata": {},
   "source": [
    "### Read File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "a8813191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n"
     ]
    }
   ],
   "source": [
    "# Decode the file\n",
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
    "# Print first 100 Characters\n",
    "print(text[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a53bdb",
   "metadata": {},
   "source": [
    "#### Total Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "671cf593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 1115394 characters\n"
     ]
    }
   ],
   "source": [
    "print(f'Length of text: {len(text)} characters')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5619d0c3",
   "metadata": {},
   "source": [
    "#### Unique Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "60758669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 unique characters\n",
      "['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(text))\n",
    "print(f'{len(vocab)} unique characters')\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75987114",
   "metadata": {},
   "source": [
    "#### Since ML training requires number, assign each character a number "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d18d8d",
   "metadata": {},
   "source": [
    "#### Each character the vocabulary will be assigned a unique number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "6dab4c6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : [UNK]\n",
      "1 : \n",
      "\n",
      "2 :  \n",
      "3 : !\n",
      "4 : $\n",
      "5 : &\n",
      "6 : '\n",
      "7 : ,\n",
      "8 : -\n",
      "9 : .\n",
      "10 : 3\n",
      "11 : :\n",
      "12 : ;\n",
      "13 : ?\n",
      "14 : A\n",
      "15 : B\n",
      "16 : C\n",
      "17 : D\n",
      "18 : E\n",
      "19 : F\n",
      "20 : G\n",
      "21 : H\n",
      "22 : I\n",
      "23 : J\n",
      "24 : K\n",
      "25 : L\n",
      "26 : M\n",
      "27 : N\n",
      "28 : O\n",
      "29 : P\n",
      "30 : Q\n",
      "31 : R\n",
      "32 : S\n",
      "33 : T\n",
      "34 : U\n",
      "35 : V\n",
      "36 : W\n",
      "37 : X\n",
      "38 : Y\n",
      "39 : Z\n",
      "40 : a\n",
      "41 : b\n",
      "42 : c\n",
      "43 : d\n",
      "44 : e\n",
      "45 : f\n",
      "46 : g\n",
      "47 : h\n",
      "48 : i\n",
      "49 : j\n",
      "50 : k\n",
      "51 : l\n",
      "52 : m\n",
      "53 : n\n",
      "54 : o\n",
      "55 : p\n",
      "56 : q\n",
      "57 : r\n",
      "58 : s\n",
      "59 : t\n",
      "60 : u\n",
      "61 : v\n",
      "62 : w\n",
      "63 : x\n",
      "64 : y\n",
      "65 : z\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' 2 corresponds to space'"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_from_chars = tf.keras.layers.StringLookup(\n",
    "    vocabulary=list(vocab), \n",
    "    mask_token=None\n",
    ")\n",
    "''' Print the vocabulary '''\n",
    "for i in range(len(ids_from_chars.get_vocabulary())):\n",
    "    print(f'{i} : {ids_from_chars.get_vocabulary()[i]}')\n",
    "    \n",
    "''' Here UNK is special Character for Out of Vocabulary Words (OOV)'''\n",
    "''' 1 corresponds to \\n '''\n",
    "''' 2 corresponds to space'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdef9ab",
   "metadata": {},
   "source": [
    "#### Here is a small example of how to convert string to numbers and back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "9e9518b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical Representation:  <tf.RaggedTensor [[26, 40, 42, 47, 48, 53, 44, 2, 25, 44, 40, 57, 53, 48, 53, 46]]>\n"
     ]
    }
   ],
   "source": [
    "example_texts = ['Machine Learning']\n",
    "chars = tf.strings.unicode_split(\n",
    "    example_texts, \n",
    "    input_encoding='UTF-8'\n",
    ")\n",
    "ids = ids_from_chars(chars)\n",
    "print(\"Numerical Representation: \",ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "35863c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character representation: \n",
      " <tf.RaggedTensor [[b'M', b'a', b'c', b'h', b'i', b'n', b'e', b' ', b'L', b'e', b'a', b'r',\n",
      "  b'n', b'i', b'n', b'g']]>\n",
      "Get String from Ids: b'Machine Learning'\n"
     ]
    }
   ],
   "source": [
    "''' This layer maps numbers to character '''\n",
    "chars_from_ids = tf.keras.layers.StringLookup(\n",
    "    vocabulary=ids_from_chars.get_vocabulary(), \n",
    "    invert=True, \n",
    "    mask_token=None\n",
    ")\n",
    "\n",
    "character_representation = chars_from_ids(ids)\n",
    "print(\"Character representation: \\n\", character_representation)\n",
    "\n",
    "string_representation = tf.strings.reduce_join(character_representation)\n",
    "print(\"Get String from Ids:\",string_representation.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "65a1b0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Creating Ids to Strings function for future use '''\n",
    "def string_from_ids(ids):\n",
    "    return tf.strings.reduce_join(chars_from_ids(ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70198684",
   "metadata": {},
   "source": [
    "## Create Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "4650f088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([19, 48, 57, ..., 46,  9,  1], dtype=int64)>"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Convert Text to numbers '''\n",
    "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
    "all_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282cbd25",
   "metadata": {},
   "source": [
    "#### Convert Ids into Tensorflow Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "60ea6547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Dataset for ids <TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>\n"
     ]
    }
   ],
   "source": [
    "''' Convert our numpy data to Tensorflow Dataset'''\n",
    "''' Tensorflow Dataset is better suited for training and is fast '''\n",
    "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)\n",
    "print(\"Tensorflow Dataset for ids\", ids_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe0ee1f",
   "metadata": {},
   "source": [
    "#### Print 10 elements from TF Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "4d95f705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At index 0: 19\n",
      "At index 1: 48\n",
      "At index 2: 57\n",
      "At index 3: 58\n",
      "At index 4: 59\n",
      "At index 5: 2\n",
      "At index 6: 16\n",
      "At index 7: 48\n",
      "At index 8: 59\n",
      "At index 9: 48\n",
      "At index 10: 65\n"
     ]
    }
   ],
   "source": [
    "k = 0\n",
    "for i in ids_dataset:\n",
    "    print(f\"At index {k}: {i}\")\n",
    "    if k >= 10:\n",
    "        break\n",
    "    k = k + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "34b58bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F\n",
      "i\n",
      "r\n",
      "s\n",
      "t\n",
      " \n",
      "C\n",
      "i\n",
      "t\n",
      "i\n"
     ]
    }
   ],
   "source": [
    "''' Better Way to do it '''\n",
    "for ids in ids_dataset.take(10):\n",
    "    ''' chars_from_ids: Converts Numbers to Characters '''\n",
    "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9af5a09",
   "metadata": {},
   "source": [
    "### How Does our training Data looks like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "b78aec60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' and so on '"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Suppose we have the words : \"Machine Learning\" '''\n",
    "''' When we input \"M\" we want our model to predict \"a\" '''\n",
    "''' When we feed in \"a\" we want our model to predict \"c\" '''\n",
    "''' and so on '''\n",
    "\n",
    "#  Input: \"Machine Learnin\"\n",
    "#  Label: \"achine Learning\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f13ae5",
   "metadata": {},
   "source": [
    "#### Create Sequences of Length 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "58aa235c",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Why are we creating batches of 100 + 1 will be clear when we create Input and Label pairs '''\n",
    "seq_length = 100\n",
    "sequences = ids_dataset.batch(\n",
    "    seq_length+1, \n",
    "    drop_remainder=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "d60d553e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[19 48 57 58 59  2 16 48 59 48 65 44 53 11  1 15 44 45 54 57 44  2 62 44\n",
      "  2 55 57 54 42 44 44 43  2 40 53 64  2 45 60 57 59 47 44 57  7  2 47 44\n",
      " 40 57  2 52 44  2 58 55 44 40 50  9  1  1 14 51 51 11  1 32 55 44 40 50\n",
      "  7  2 58 55 44 40 50  9  1  1 19 48 57 58 59  2 16 48 59 48 65 44 53 11\n",
      "  1 38 54 60  2], shape=(101,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[b'F' b'i' b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':'\n",
      " b'\\n' b'B' b'e' b'f' b'o' b'r' b'e' b' ' b'w' b'e' b' ' b'p' b'r' b'o'\n",
      " b'c' b'e' b'e' b'd' b' ' b'a' b'n' b'y' b' ' b'f' b'u' b'r' b't' b'h'\n",
      " b'e' b'r' b',' b' ' b'h' b'e' b'a' b'r' b' ' b'm' b'e' b' ' b's' b'p'\n",
      " b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'A' b'l' b'l' b':' b'\\n' b'S' b'p' b'e'\n",
      " b'a' b'k' b',' b' ' b's' b'p' b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'F' b'i'\n",
      " b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':' b'\\n' b'Y'\n",
      " b'o' b'u' b' '], shape=(101,), dtype=string)\n",
      "\n",
      " b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
      "\n",
      " b'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n",
      "\n",
      " b\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n",
      "\n",
      " b\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n",
      "\n",
      " b'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"
     ]
    }
   ],
   "source": [
    "''' Sequences in Numbers '''\n",
    "for seq in sequences.take(1):\n",
    "    print(seq)\n",
    "    \n",
    "''' Sequences in Characters '''\n",
    "for seq in sequences.take(1):\n",
    "    print(chars_from_ids(seq))\n",
    "    \n",
    "''' Sequences in strings '''\n",
    "for seq in sequences.take(5):\n",
    "    print(\"\\n\",string_from_ids(seq).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2ce68a",
   "metadata": {},
   "source": [
    "### Create Input and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "a230083b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['M', 'a', 'c', 'h', 'i', 'n', 'e', ' ', 'L', 'e', 'a', 'r', 'n', 'i', 'n'],\n",
       " ['a', 'c', 'h', 'i', 'n', 'e', ' ', 'L', 'e', 'a', 'r', 'n', 'i', 'n', 'g'])"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' This function will take 101 length Sequence and create Input and Label '''\n",
    "''' Input: 0-99 Characters '''\n",
    "''' Label: 1:100 Characters '''\n",
    "def split_input_target(sequence):\n",
    "    input_text = sequence[:-1]\n",
    "    target_text = sequence[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "'''Example '''\n",
    "split_input_target(list(\"Machine Learning\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "c6a08863",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "6582c763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou', shape=(), dtype=string)\n",
      "tf.Tensor(b'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou ', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for inputs, labels in dataset.take(1):\n",
    "    print(string_from_ids(inputs))\n",
    "    print(string_from_ids(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b787cea7",
   "metadata": {},
   "source": [
    "### Create Training Batches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "4aa69f3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "buffer_size = 1024\n",
    "\n",
    "dataset = (\n",
    "    dataset\n",
    "    .shuffle(buffer_size)\n",
    "    .batch(batch_size, drop_remainder=True)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
    ")\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8d85ff",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "68817e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Set Parameters '''\n",
    "vocab_size = len(ids_from_chars.get_vocabulary())\n",
    "embedding_dimensions = 256\n",
    "LSTM_Cells = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4154605",
   "metadata": {},
   "source": [
    "###  Model: Input -> Embedding_layer -> GRU_Layer -> Dense -> Softmax "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ad0821",
   "metadata": {},
   "source": [
    "### Stateless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "9d1840ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " Embedding_Layer (Embedding)  (None, None, 256)        16896     \n",
      "                                                                 \n",
      " GRU_Layer (GRU)             (None, None, 1024)        3938304   \n",
      "                                                                 \n",
      " Dense_Layer (Dense)         (None, None, 66)          67650     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,022,850\n",
      "Trainable params: 4,022,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "''' Our Input length is Sequence length: 100'''\n",
    "x = tf.keras.layers.Input(shape=(None, ))\n",
    "\n",
    "''' Each id in Vocabulary is mapped to a 256 length vector '''\n",
    "embeddings = tf.keras.layers.Embedding(\n",
    "    input_dim=vocab_size, \n",
    "    output_dim=embedding_dimensions,\n",
    "    name=\"Embedding_Layer\"\n",
    ")(x)\n",
    "\n",
    "''' GRU Layer '''\n",
    "gru_output = tf.keras.layers.GRU(\n",
    "    units=LSTM_Cells,\n",
    "    return_sequences=True,\n",
    "    name=\"GRU_Layer\"\n",
    ")(embeddings)\n",
    "\n",
    "''' Prediction layer '''\n",
    "prediction = tf.keras.layers.Dense(\n",
    "    units=vocab_size,\n",
    "    name=\"Dense_Layer\"\n",
    ")(gru_output)\n",
    "\n",
    "model = tf.keras.Model(inputs=x, outputs=prediction)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71175f6",
   "metadata": {},
   "source": [
    "### Stateful"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9433aba2",
   "metadata": {},
   "source": [
    "#### Make a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "6e40dd5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input : tf.Tensor(b'us.\\n\\nTITUS:\\n\\nCOMINIUS:\\nNoble Marcius!\\n\\nFirst Senator:\\n\\nMARCIUS:\\nNay, let them follow:\\nThe Volsces ha', shape=(), dtype=string)\n",
      "Label : tf.Tensor(b's.\\n\\nTITUS:\\n\\nCOMINIUS:\\nNoble Marcius!\\n\\nFirst Senator:\\n\\nMARCIUS:\\nNay, let them follow:\\nThe Volsces hav', shape=(), dtype=string)\n",
      "Batch Size:  64\n",
      "Sequence Length:  100\n",
      "Vocabulary Size:  66\n"
     ]
    }
   ],
   "source": [
    "for inputs, labels in dataset.take(1):\n",
    "    sampled_input, sampled_label = inputs, labels\n",
    "    print(\"Input :\", string_from_ids(inputs[0]))\n",
    "    print(\"Label :\", string_from_ids(labels[0]))\n",
    "    prediction = model(inputs)\n",
    "    print(\"Batch Size: \",prediction.shape[0])\n",
    "    print(\"Sequence Length: \",prediction.shape[1])\n",
    "    print(\"Vocabulary Size: \",prediction.shape[2])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "60d73e65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_string_from_prediction(prediction):\n",
    "    ''' Get max probability index for each sequence '''\n",
    "    ids = tf.argmax(prediction, axis=1)\n",
    "    ''' Get the string '''\n",
    "    return string_from_ids(ids.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "a8ae1e86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  tf.Tensor(\n",
      "[[ 4.55405377e-03 -1.28299426e-02  1.11228914e-03 ... -1.53576443e-03\n",
      "  -9.77340154e-04  3.24896071e-03]\n",
      " [ 1.19512435e-04  1.02393366e-02  4.00568498e-03 ... -5.52313868e-04\n",
      "   2.45948974e-03  7.68733630e-03]\n",
      " [ 4.41037584e-03 -3.49492906e-03  3.57401767e-03 ... -7.55473366e-03\n",
      "   4.11812216e-05 -9.83093167e-04]\n",
      " ...\n",
      " [-7.03154411e-03  9.24186874e-03 -5.23744617e-04 ...  1.31909810e-02\n",
      "   7.82135688e-03 -1.64746866e-03]\n",
      " [-5.96299209e-03  5.14188781e-03 -1.68444533e-02 ...  5.89163601e-03\n",
      "   7.41392467e-03  1.47369690e-04]\n",
      " [-9.43620130e-03 -6.11680932e-03 -1.44772707e-02 ...  7.31437583e-04\n",
      "  -9.78195225e-04  1.46481795e-02]], shape=(100, 66), dtype=float32)\n",
      "Text representation:  tf.Tensor(b'tGGh 3SSb,Soo  lhRRPVSoRRxCc;;lBd!thihh:pohhKVmSSSJoooolh\\nVabVSoRR.L;KSS!nSSC;TEECECCo3SS;LJCG-mk;!S', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "''' Untrained model results '''\n",
    "print(\"Prediction: \", prediction[0])\n",
    "print(\"Text representation: \", get_string_from_prediction(prediction[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243dbe42",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "9f2d57ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c319b664",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "9b7689ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "4ead5267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_dir/stateless/v3'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "05d8df9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "172/172 [==============================] - 5s 24ms/step - loss: 0.6882\n",
      "Epoch 2/100\n",
      "172/172 [==============================] - 4s 25ms/step - loss: 0.6548\n",
      "Epoch 3/100\n",
      "172/172 [==============================] - 4s 25ms/step - loss: 0.6247\n",
      "Epoch 4/100\n",
      "172/172 [==============================] - 4s 25ms/step - loss: 0.6042\n",
      "Epoch 5/100\n",
      "172/172 [==============================] - 4s 25ms/step - loss: 0.5829\n",
      "Epoch 6/100\n",
      "172/172 [==============================] - 4s 25ms/step - loss: 0.5635\n",
      "Epoch 7/100\n",
      "172/172 [==============================] - 4s 25ms/step - loss: 0.5492\n",
      "Epoch 8/100\n",
      "172/172 [==============================] - 4s 26ms/step - loss: 0.5354\n",
      "Epoch 9/100\n",
      "172/172 [==============================] - 4s 25ms/step - loss: 0.5252\n",
      "Epoch 10/100\n",
      "172/172 [==============================] - 4s 25ms/step - loss: 0.5157\n",
      "Epoch 11/100\n",
      "172/172 [==============================] - 4s 25ms/step - loss: 0.5080\n",
      "Epoch 12/100\n",
      "172/172 [==============================] - 4s 25ms/step - loss: 0.5025\n",
      "Epoch 13/100\n",
      "172/172 [==============================] - 4s 26ms/step - loss: 0.4931\n",
      "Epoch 14/100\n",
      "172/172 [==============================] - 4s 26ms/step - loss: 0.4870\n",
      "Epoch 15/100\n",
      "172/172 [==============================] - 4s 26ms/step - loss: 0.4861\n",
      "Epoch 16/100\n",
      "172/172 [==============================] - 5s 26ms/step - loss: 0.4793\n",
      "Epoch 17/100\n",
      "172/172 [==============================] - 5s 27ms/step - loss: 0.4759\n",
      "Epoch 18/100\n",
      "172/172 [==============================] - 5s 28ms/step - loss: 0.4715\n",
      "Epoch 19/100\n",
      "172/172 [==============================] - 5s 28ms/step - loss: 0.4692\n",
      "Epoch 20/100\n",
      "172/172 [==============================] - 5s 29ms/step - loss: 0.4677\n",
      "Epoch 21/100\n",
      "172/172 [==============================] - 5s 29ms/step - loss: 0.4667\n",
      "Epoch 22/100\n",
      "172/172 [==============================] - 5s 30ms/step - loss: 0.4623\n",
      "Epoch 23/100\n",
      "172/172 [==============================] - 5s 29ms/step - loss: 0.4613\n",
      "Epoch 24/100\n",
      "172/172 [==============================] - 5s 29ms/step - loss: 0.4544\n",
      "Epoch 25/100\n",
      "172/172 [==============================] - 5s 29ms/step - loss: 0.4541\n",
      "Epoch 26/100\n",
      "172/172 [==============================] - 5s 29ms/step - loss: 0.4571\n",
      "Epoch 27/100\n",
      "172/172 [==============================] - 5s 30ms/step - loss: 0.4567\n",
      "Epoch 28/100\n",
      "172/172 [==============================] - 5s 30ms/step - loss: 0.4530\n",
      "Epoch 29/100\n",
      "172/172 [==============================] - 5s 30ms/step - loss: 0.4480\n",
      "Epoch 30/100\n",
      "172/172 [==============================] - 5s 30ms/step - loss: 0.4467\n",
      "Epoch 31/100\n",
      "172/172 [==============================] - 5s 30ms/step - loss: 0.4484\n",
      "Epoch 32/100\n",
      "172/172 [==============================] - 5s 30ms/step - loss: 0.4517\n",
      "Epoch 33/100\n",
      "172/172 [==============================] - 5s 30ms/step - loss: 0.4547\n",
      "Epoch 34/100\n",
      "172/172 [==============================] - 5s 30ms/step - loss: 0.4586\n",
      "Epoch 35/100\n",
      "172/172 [==============================] - 5s 30ms/step - loss: 0.4556\n",
      "Epoch 36/100\n",
      "172/172 [==============================] - 5s 30ms/step - loss: 0.4509\n",
      "Epoch 37/100\n",
      "172/172 [==============================] - 5s 30ms/step - loss: 0.4446\n",
      "Epoch 38/100\n",
      "172/172 [==============================] - 5s 30ms/step - loss: 0.4494\n",
      "Epoch 39/100\n",
      "172/172 [==============================] - 5s 30ms/step - loss: 0.4499\n",
      "Epoch 40/100\n",
      "172/172 [==============================] - 5s 30ms/step - loss: 0.4569\n",
      "Epoch 41/100\n",
      "172/172 [==============================] - 5s 30ms/step - loss: 0.4602\n",
      "Epoch 42/100\n",
      "172/172 [==============================] - 5s 30ms/step - loss: 0.4599\n",
      "Epoch 43/100\n",
      "172/172 [==============================] - 5s 30ms/step - loss: 0.4597\n",
      "Epoch 44/100\n",
      "172/172 [==============================] - 5s 30ms/step - loss: 0.4610\n",
      "Epoch 45/100\n",
      "172/172 [==============================] - 5s 32ms/step - loss: 0.4613\n",
      "Epoch 46/100\n",
      "172/172 [==============================] - 5s 31ms/step - loss: 0.4615\n",
      "Epoch 47/100\n",
      "172/172 [==============================] - 5s 31ms/step - loss: 0.4624\n",
      "Epoch 48/100\n",
      "172/172 [==============================] - 5s 31ms/step - loss: 0.4650\n",
      "Epoch 49/100\n",
      "172/172 [==============================] - 5s 30ms/step - loss: 0.4721\n",
      "Epoch 50/100\n",
      "172/172 [==============================] - 5s 29ms/step - loss: 0.4674\n",
      "Epoch 51/100\n",
      "172/172 [==============================] - 5s 30ms/step - loss: 0.4701\n",
      "Epoch 52/100\n",
      "172/172 [==============================] - 5s 31ms/step - loss: 0.4681\n",
      "Epoch 53/100\n",
      "172/172 [==============================] - 5s 31ms/step - loss: 0.4742\n",
      "Epoch 54/100\n",
      "172/172 [==============================] - 5s 31ms/step - loss: 0.4738\n",
      "Epoch 55/100\n",
      "172/172 [==============================] - 5s 31ms/step - loss: 0.4778\n",
      "Epoch 56/100\n",
      "172/172 [==============================] - 5s 31ms/step - loss: 0.4767\n",
      "Epoch 57/100\n",
      "172/172 [==============================] - 5s 31ms/step - loss: 0.4807\n",
      "Epoch 58/100\n",
      "172/172 [==============================] - 5s 31ms/step - loss: 0.4882\n",
      "Epoch 59/100\n",
      "172/172 [==============================] - 5s 31ms/step - loss: 0.4877\n",
      "Epoch 60/100\n",
      "172/172 [==============================] - 5s 29ms/step - loss: 0.4924\n",
      "Epoch 61/100\n",
      "172/172 [==============================] - 5s 30ms/step - loss: 0.4933\n",
      "Epoch 62/100\n",
      "172/172 [==============================] - 5s 31ms/step - loss: 0.4915\n",
      "Epoch 63/100\n",
      "172/172 [==============================] - 5s 31ms/step - loss: 0.4954\n",
      "Epoch 64/100\n",
      "172/172 [==============================] - 5s 31ms/step - loss: 0.5018\n",
      "Epoch 65/100\n",
      "172/172 [==============================] - 5s 31ms/step - loss: 0.5032\n",
      "Epoch 66/100\n",
      "172/172 [==============================] - 5s 31ms/step - loss: 0.5018\n",
      "Epoch 67/100\n",
      "172/172 [==============================] - 5s 31ms/step - loss: 0.5066\n",
      "Epoch 68/100\n",
      "172/172 [==============================] - 5s 30ms/step - loss: 0.5118\n",
      "Epoch 69/100\n",
      "172/172 [==============================] - 5s 31ms/step - loss: 0.5206\n",
      "Epoch 70/100\n",
      "172/172 [==============================] - 5s 31ms/step - loss: 0.5229\n",
      "Epoch 71/100\n",
      "172/172 [==============================] - 5s 31ms/step - loss: 0.5245\n",
      "Epoch 72/100\n",
      "172/172 [==============================] - 5s 31ms/step - loss: 0.5274\n",
      "Epoch 73/100\n",
      "172/172 [==============================] - 5s 31ms/step - loss: 0.5312\n",
      "Epoch 74/100\n",
      "172/172 [==============================] - 5s 31ms/step - loss: 0.5350\n",
      "Epoch 75/100\n",
      "172/172 [==============================] - 5s 31ms/step - loss: 0.5352\n",
      "Epoch 76/100\n",
      "172/172 [==============================] - 5s 31ms/step - loss: 0.5494\n",
      "Epoch 77/100\n",
      "172/172 [==============================] - 5s 31ms/step - loss: 0.5554\n",
      "Epoch 78/100\n",
      "172/172 [==============================] - 5s 31ms/step - loss: 0.5538\n",
      "Epoch 79/100\n",
      "172/172 [==============================] - 5s 31ms/step - loss: 0.5623\n",
      "Epoch 80/100\n",
      "172/172 [==============================] - 5s 31ms/step - loss: 0.5739\n",
      "Epoch 81/100\n",
      "172/172 [==============================] - 5s 31ms/step - loss: 0.5864\n",
      "Epoch 82/100\n",
      "172/172 [==============================] - 5s 31ms/step - loss: 0.5887\n",
      "Epoch 83/100\n",
      "172/172 [==============================] - 5s 31ms/step - loss: 0.5916\n",
      "Epoch 84/100\n",
      "172/172 [==============================] - 5s 31ms/step - loss: 0.6019\n",
      "Epoch 85/100\n",
      "172/172 [==============================] - 5s 31ms/step - loss: 0.6024\n",
      "Epoch 86/100\n",
      "172/172 [==============================] - 5s 30ms/step - loss: 0.6080\n",
      "Epoch 87/100\n",
      "172/172 [==============================] - 5s 30ms/step - loss: 0.6174\n",
      "Epoch 88/100\n",
      "172/172 [==============================] - 5s 30ms/step - loss: 0.6339\n",
      "Epoch 89/100\n",
      "172/172 [==============================] - 5s 31ms/step - loss: 0.6432\n",
      "Epoch 90/100\n",
      "172/172 [==============================] - 5s 31ms/step - loss: 0.6432\n",
      "Epoch 91/100\n",
      "172/172 [==============================] - 5s 31ms/step - loss: 0.6462\n",
      "Epoch 92/100\n",
      "172/172 [==============================] - 5s 30ms/step - loss: 0.6545\n",
      "Epoch 93/100\n",
      "172/172 [==============================] - 5s 31ms/step - loss: 0.6822\n",
      "Epoch 94/100\n",
      "172/172 [==============================] - 5s 31ms/step - loss: 0.6931\n",
      "Epoch 95/100\n",
      "172/172 [==============================] - 5s 31ms/step - loss: 0.6988\n",
      "Epoch 96/100\n",
      "172/172 [==============================] - 5s 30ms/step - loss: 0.7066\n",
      "Epoch 97/100\n",
      "172/172 [==============================] - 5s 31ms/step - loss: 0.7216\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 5s 31ms/step - loss: 0.7284\n",
      "Epoch 99/100\n",
      "172/172 [==============================] - 5s 31ms/step - loss: 0.7305\n",
      "Epoch 100/100\n",
      "172/172 [==============================] - 5s 30ms/step - loss: 0.7475\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "history = model.fit(\n",
    "    dataset, \n",
    "    epochs=EPOCHS, \n",
    "    callbacks=[checkpoint_callback],\n",
    "    workers=8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa96ebc",
   "metadata": {},
   "source": [
    "#### Load Model from Checkpoint if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "12daa95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights('./training_dir/stateless/v2/ckpt_19')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ce7452",
   "metadata": {},
   "source": [
    "#### Saved Model as h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "c3a81eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('./saved_model/stateless_ml.h5')\n",
    "# model = tf.keras.models.load_model('./saved_model/stateless_ml.h5')\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805a048f",
   "metadata": {},
   "source": [
    "### Set probability of UNK character to -inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "17fd9426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0]], shape=(1, 1), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "''' Get index of UNK and expand dims using [:,None]'''\n",
    "unk_index = ids_from_chars(['[UNK]'])\n",
    "unk_index = tf.expand_dims(unk_index, axis=0)\n",
    "print(unk_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "aebee579",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' This mask takes the index of UNK i.e. 0. Index needs to be 2d array '''\n",
    "''' Sets it value to -inf (we can add more indexes to -inf if needed) '''\n",
    "''' And outputs an array of size len(vocabulary)'''\n",
    "skip_ids = unk_index\n",
    "sparse_mask = tf.SparseTensor(\n",
    "    indices=skip_ids,\n",
    "    values=[-float('inf')]*len(skip_ids),\n",
    "    dense_shape=[len(ids_from_chars.get_vocabulary())]\n",
    ")\n",
    "\n",
    "''' Create the array using the sparse_mask'''\n",
    "prediction_mask = tf.sparse.to_dense(sparse_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "c6ff517a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[-inf   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.], shape=(66,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(prediction_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17212a0",
   "metadata": {},
   "source": [
    "#### Create prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "990ddeec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n",
      "(54,)\n"
     ]
    }
   ],
   "source": [
    "''' Test String '''\n",
    "input_to_model = \"Second Citizen:\\nWould \\nAll:\\nAgainst him first: he's a \"\n",
    "print(len(input_to_model))\n",
    "\n",
    "# Convert strings to token IDs.\n",
    "input_chars = tf.strings.unicode_split(input_to_model, 'UTF-8')\n",
    "input_ids = ids_from_chars(input_chars)\n",
    "print(input_ids.shape)\n",
    "''' Reshaping to [1, 100, 256]'''\n",
    "input_ids = tf.expand_dims(input_ids, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "85d4dd7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of prediction (1, 54, 66)\n"
     ]
    }
   ],
   "source": [
    "''' Make prediction '''\n",
    "predicted_logits = model(input_ids)\n",
    "print(\"Shape of prediction\", predicted_logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "136aa28c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Prediction:  tf.Tensor(\n",
      "[[ -9.246437   -17.632954    -9.689228   -12.72849     -9.112964\n",
      "   -9.590695    -9.763602   -13.179567   -13.928673   -13.362494\n",
      "  -16.017387   -12.148553    -9.504623   -19.8527     -13.070886\n",
      "   -0.4352389    1.6912851   -4.4968443   -2.7709296   -2.88457\n",
      "   -7.7103333    0.5006807   -0.9558542    0.7200699    2.1808965\n",
      "   -1.5422612    5.142561    -2.2195165  -10.284126     4.313134\n",
      "   -5.0606885    4.0031476   -1.4036236   -3.4693992  -16.445179\n",
      "   -8.638715    -5.4636188   -7.1255817   -8.771386   -13.710989\n",
      "   -0.9573246    8.75647      3.3905513    8.47859     -1.7532681\n",
      "    9.405699     7.0267553    8.103318     0.13917461   0.8375107\n",
      "    6.97197      9.272437     8.935901     4.312721    -0.60793453\n",
      "   10.420002     0.81972086   9.751318     7.719472     8.160555\n",
      "   -0.22633009   6.89016      6.2521358   -6.127429     3.5153356\n",
      "   -6.3698115 ]], shape=(1, 66), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "''' Only Use the last prediction '''\n",
    "predicted_logits = predicted_logits[:, -1, :]\n",
    "print(\"Last Prediction: \",predicted_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "85806d64",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated prediction logits:  tf.Tensor(\n",
      "[[        -inf -17.632954    -9.689228   -12.72849     -9.112964\n",
      "   -9.590695    -9.763602   -13.179567   -13.928673   -13.362494\n",
      "  -16.017387   -12.148553    -9.504623   -19.8527     -13.070886\n",
      "   -0.4352389    1.6912851   -4.4968443   -2.7709296   -2.88457\n",
      "   -7.7103333    0.5006807   -0.9558542    0.7200699    2.1808965\n",
      "   -1.5422612    5.142561    -2.2195165  -10.284126     4.313134\n",
      "   -5.0606885    4.0031476   -1.4036236   -3.4693992  -16.445179\n",
      "   -8.638715    -5.4636188   -7.1255817   -8.771386   -13.710989\n",
      "   -0.9573246    8.75647      3.3905513    8.47859     -1.7532681\n",
      "    9.405699     7.0267553    8.103318     0.13917461   0.8375107\n",
      "    6.97197      9.272437     8.935901     4.312721    -0.60793453\n",
      "   10.420002     0.81972086   9.751318     7.719472     8.160555\n",
      "   -0.22633009   6.89016      6.2521358   -6.127429     3.5153356\n",
      "   -6.3698115 ]], shape=(1, 66), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "predicted_logits = predicted_logits + prediction_mask\n",
    "print(\"Updated prediction logits: \",predicted_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "dfc6ad78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Id:  tf.Tensor(51, shape=(), dtype=int64)\n",
      "Prediction Character:  tf.Tensor(b'l', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "''' Sample from the distribution '''\n",
    "''' It is important to sample from this distribution '''\n",
    "''' as taking the argmax of the distribution can easily get the model stuck in a loop. '''\n",
    "prediction_id = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "print(\"Prediction Id: \", prediction_id[0,0])\n",
    "print(\"Prediction Character: \", chars_from_ids(prediction_id[0,0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "de406867",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Combining the above step into a function\n",
    "def one_step_prediction(input_chars):\n",
    "    ''' Convert to Integers'''\n",
    "    input_ids = ids_from_chars(tf.strings.unicode_split(input_chars, 'UTF-8'))\n",
    "    input_ids = tf.expand_dims(input_ids, axis=0)\n",
    "    \n",
    "    ''' Make Prediction '''\n",
    "    predicted_logits = model(input_ids)\n",
    "    \n",
    "    ''' Get Last Prediction & Apply Mask '''\n",
    "    last_pred = predicted_logits[:, -1, :]\n",
    "    last_pred = last_pred + prediction_mask\n",
    "    ''' Sample an output '''\n",
    "    prediction_id = tf.random.categorical(last_pred, num_samples=1)\n",
    "    prediction_id = tf.squeeze(prediction_id, axis=-1)\n",
    "    \n",
    "    ''' Return Characted'''\n",
    "    return chars_from_ids(prediction_id)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "ddc80a2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMEO:\n",
      "UMyorater sead VETRONELIScous tr hareke\n",
      "Biofavie when be.\n",
      "ARO:\n",
      "THete thelfevin alaiod y.\n",
      "\n",
      "KEnonge,\n",
      "O, vetos, IORD he?\n",
      "Prees a tu bor.\n",
      "Tho.\n",
      "Ano, ier:\n",
      "\n",
      "WANCllitoofftheraus fomen, s menopler d atwe inco for?\n",
      "Ve come, IO:\n",
      "I d,\n",
      "ONCHeencogo buncon ay s anican oth, rea n gofor\n",
      "ANCINofoullirestryoug s,\n",
      "ICERYoutathize\n",
      "ORIUEl.\n",
      "S:\n",
      "ORird:\n",
      "HAND gacofaneencin; pee s y my w s he-th coreat ha amizerorast oss,\n",
      "Thorgeasthealu a se a stou he;\n",
      "BEO:\n",
      "Be;\n",
      "A:\n",
      "CKal deareve\n",
      "We ote sp my tinou,\n",
      "Whan a f d ise my iroldomeshathy thevens t, ganomireathy;\n",
      "THily at! helath s,\n",
      "\n",
      "KE:\n",
      "STRe ecusersousone,\n",
      "I:\n",
      "Anofe.\n",
      "A: hare hath jul RDYoofowoul.\n",
      "A williore,\n",
      "Homyoutwio I t, I o, fouplo;\n",
      "\n",
      "STheeles ftis hathee, and;\n",
      "PELIDURTeve w t o n,\n",
      "\n",
      "Ther'd maichous weato mybyiokeadyouldrsbea t TETonthe fant melout IO:\n",
      "Ticube d h yofier weenoud te w the sst r h of ce denoutas ioove iowee IORYo, suthonld d st pr, otor fo wnd my t hatu d hest ORIENO:\n",
      "ORD a ho gate ie,\n",
      "Wis omal waseo ng my\n",
      "\n",
      "A: the s y horond swexeg,\n",
      "TOuts, rut, ELORYor'se't\n"
     ]
    }
   ],
   "source": [
    "next_char = tf.constant('ROMEO:')\n",
    "result = []\n",
    "result.append([next_char])\n",
    "\n",
    "for n in range(1000):\n",
    "    next_char = one_step_prediction(next_char)\n",
    "    result.append([next_char])\n",
    "\n",
    "''' Combine all stings '''\n",
    "res = tf.strings.join(result)\n",
    "''' Print Output'''\n",
    "print(res.numpy()[0].decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28d6406",
   "metadata": {},
   "source": [
    "# Stateful LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "efdfb2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_13 (InputLayer)       [(64, None)]              0         \n",
      "                                                                 \n",
      " Embedding_Layer (Embedding)  (64, None, 256)          16896     \n",
      "                                                                 \n",
      " GRU_Layer (GRU)             (64, None, 1024)          3938304   \n",
      "                                                                 \n",
      " Dense_Layer (Dense)         (64, None, 66)            67650     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,022,850\n",
      "Trainable params: 4,022,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "''' Our Input length is Sequence length: 100'''\n",
    "x = tf.keras.layers.Input(\n",
    "    shape=(None, ),\n",
    "    batch_size=64\n",
    ")\n",
    "\n",
    "''' Each id in Vocabulary is mapped to a 256 length vector '''\n",
    "embeddings = tf.keras.layers.Embedding(\n",
    "    input_dim=vocab_size, \n",
    "    output_dim=embedding_dimensions,\n",
    "    name=\"Embedding_Layer\"\n",
    ")(x)\n",
    "\n",
    "''' GRU Layer '''\n",
    "gru_output = tf.keras.layers.GRU(\n",
    "    units=LSTM_Cells,\n",
    "    return_sequences=True,\n",
    "    stateful=True,\n",
    "    name=\"GRU_Layer\"\n",
    ")(embeddings)\n",
    "\n",
    "''' Prediction layer '''\n",
    "prediction = tf.keras.layers.Dense(\n",
    "    units=vocab_size,\n",
    "    name=\"Dense_Layer\"\n",
    ")(gru_output)\n",
    "\n",
    "model_stateful = tf.keras.Model(inputs=x, outputs=[prediction])\n",
    "model_stateful.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db121d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "loss_function = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_dir/stateful/v2'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73af85d8",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "bec8351b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_function(model_stateful, inputs):\n",
    "    X, label = inputs\n",
    "    with tf.GradientTape() as tape:\n",
    "        prediction = model_stateful(X)\n",
    "        loss = loss_function(label, prediction)\n",
    "    training_variables = model_stateful.trainable_variables\n",
    "    gradient = tape.gradient(loss, training_variables)\n",
    "    optimizer.apply_gradients(zip(gradient, training_variables))\n",
    "    return {'loss':loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "787d7b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 2.7245\n",
      "Epoch 2 Loss: 2.3704\n",
      "Epoch 3 Loss: 2.1681\n",
      "Epoch 4 Loss: 2.0265\n",
      "Epoch 5 Loss: 1.9210\n",
      "Epoch 6 Loss: 1.8393\n",
      "Epoch 7 Loss: 1.7739\n",
      "Epoch 8 Loss: 1.7196\n",
      "Epoch 9 Loss: 1.6735\n",
      "Epoch 10 Loss: 1.6334\n",
      "Epoch 11 Loss: 1.5976\n",
      "Epoch 12 Loss: 1.5652\n",
      "Epoch 13 Loss: 1.5353\n",
      "Epoch 14 Loss: 1.5073\n",
      "Epoch 15 Loss: 1.4808\n",
      "Epoch 16 Loss: 1.4554\n",
      "Epoch 17 Loss: 1.4309\n",
      "Epoch 18 Loss: 1.4072\n",
      "Epoch 19 Loss: 1.3841\n",
      "Epoch 20 Loss: 1.3615\n"
     ]
    }
   ],
   "source": [
    "mean = tf.metrics.Mean()\n",
    "state = None\n",
    "for epoch in range(20):\n",
    "    loss = 0\n",
    "    for (batch_n, (inp, target)) in enumerate(dataset):\n",
    "        logs = train_function(model_stateful, [inp, target])\n",
    "        mean.update_state(logs['loss'])\n",
    "        \n",
    "    ''' Print Loss for an epoch'''\n",
    "    print(f'Epoch {epoch+1} Loss: {mean.result().numpy():.4f}')\n",
    "    \n",
    "    ''' Save every 5th Epoch model '''\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        model_stateful.save_weights(checkpoint_prefix.format(epoch=epoch))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c229c581",
   "metadata": {},
   "source": [
    "### Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "02be4419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_14 (InputLayer)       [(1, None)]               0         \n",
      "                                                                 \n",
      " Embedding_Layer (Embedding)  (1, None, 256)           16896     \n",
      "                                                                 \n",
      " GRU_Layer (GRU)             (1, None, 1024)           3938304   \n",
      "                                                                 \n",
      " Dense_Layer (Dense)         (1, None, 66)             67650     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,022,850\n",
      "Trainable params: 4,022,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "''' Our Input length is Sequence length: 100'''\n",
    "x = tf.keras.layers.Input(\n",
    "    shape=(None, ),\n",
    "    batch_size=1\n",
    ")\n",
    "\n",
    "''' Each id in Vocabulary is mapped to a 256 length vector '''\n",
    "embeddings = tf.keras.layers.Embedding(\n",
    "    input_dim=vocab_size, \n",
    "    output_dim=embedding_dimensions,\n",
    "    name=\"Embedding_Layer\"\n",
    ")(x)\n",
    "\n",
    "''' GRU Layer '''\n",
    "gru_output = tf.keras.layers.GRU(\n",
    "    units=LSTM_Cells,\n",
    "    return_sequences=True,\n",
    "    stateful=True,\n",
    "    name=\"GRU_Layer\"\n",
    ")(embeddings)\n",
    "\n",
    "''' Prediction layer '''\n",
    "prediction = tf.keras.layers.Dense(\n",
    "    units=vocab_size,\n",
    "    name=\"Dense_Layer\"\n",
    ")(gru_output)\n",
    "\n",
    "new_model_stateful = tf.keras.Model(inputs=x, outputs=[prediction])\n",
    "new_model_stateful.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "af7bb77a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x1ffe61b2620>"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model_stateful.load_weights('./training_dir/stateful/v2/ckpt_19')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "cdf634f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Combining the above step into a function\n",
    "def one_step_prediction_stateful(model_stateful, input_chars):\n",
    "    ''' Convert to Integers'''\n",
    "    input_ids = ids_from_chars(tf.strings.unicode_split(input_chars, 'UTF-8'))\n",
    "    input_ids = tf.expand_dims(input_ids, axis=0)\n",
    "    \n",
    "    ''' Make Prediction '''\n",
    "    predicted_logits = model_stateful(input_ids)\n",
    "    ''' Get Last Prediction & Apply Mask '''\n",
    "    last_pred = predicted_logits[:, -1, :]\n",
    "    last_pred = last_pred + prediction_mask\n",
    "    ''' Sample an output '''\n",
    "    prediction_id = tf.random.categorical(last_pred, num_samples=1)\n",
    "    prediction_id = tf.squeeze(prediction_id, axis=-1)\n",
    "    \n",
    "    ''' Return Characted'''\n",
    "    return chars_from_ids(prediction_id)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "3f68554d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMEO:\n",
      "First, bad despised, shall straight I know\n",
      "Out of their neither accessith; but I fear my father, brought to that?\n",
      "\n",
      "HORTENSIO:\n",
      "The vabour is wondrous question,--\n",
      "For God's sake, nancius, your fortunes forgit you study by hers,\n",
      "For in a trunk and nicely-wench we let them very haste:\n",
      "There to that art thine.\n",
      "\n",
      "LUCENTIO:\n",
      "The gods sir, were you so curst in fault, and nothing of all\n",
      "My masters for thee man! withto his state, will rise or seven,\n",
      "Keave stands, betwixt us. But I shall not be savian:\n",
      "The more my lord but what you are.\n",
      "\n",
      "Petake horn-bed.\n",
      "And, let it straight.\n",
      "\n",
      "PETRUCHIO:\n",
      "He's a husband for it shall, I fear, a boy.\n",
      "\n",
      "CLAUDIO:\n",
      "Lendle Ledjul's foot.\n",
      "My bridal drount; I love not ot could spiet upon my husband.\n",
      "Gong to his welcomed for you;\n",
      "I, how he being, O, what either appliar,\n",
      "And hold to her down for Baptista should be mine:\n",
      "Do he might wear the clouds, as Every stage and good would incide no more; and craces this of his sustaining starms\n",
      "Perduard an evil of my foot,\n",
      "That till\n",
      "When\n"
     ]
    }
   ],
   "source": [
    "next_char = tf.constant('ROMEO:')\n",
    "result = []\n",
    "result.append([next_char])\n",
    "\n",
    "for n in range(1000):\n",
    "    next_char = one_step_prediction_stateful(new_model_stateful, next_char)\n",
    "    result.append([next_char])\n",
    "res = tf.strings.join(result)\n",
    "print(res.numpy()[0].decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8f8563",
   "metadata": {},
   "source": [
    "### Stateful uising fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "5eafdb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_16 (InputLayer)       [(64, None)]              0         \n",
      "                                                                 \n",
      " Embedding_Layer (Embedding)  (64, None, 256)          16896     \n",
      "                                                                 \n",
      " GRU_Layer (GRU)             (64, None, 1024)          3938304   \n",
      "                                                                 \n",
      " Dense_Layer (Dense)         (64, None, 66)            67650     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,022,850\n",
      "Trainable params: 4,022,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "''' Our Input length is Sequence length: 100'''\n",
    "x = tf.keras.layers.Input(\n",
    "    shape=(None, ),\n",
    "    batch_size=64\n",
    ")\n",
    "\n",
    "''' Each id in Vocabulary is mapped to a 256 length vector '''\n",
    "embeddings = tf.keras.layers.Embedding(\n",
    "    input_dim=vocab_size, \n",
    "    output_dim=embedding_dimensions,\n",
    "    name=\"Embedding_Layer\"\n",
    ")(x)\n",
    "\n",
    "''' GRU Layer '''\n",
    "gru_output = tf.keras.layers.GRU(\n",
    "    units=LSTM_Cells,\n",
    "    return_sequences=True,\n",
    "    stateful=True,\n",
    "    name=\"GRU_Layer\"\n",
    ")(embeddings)\n",
    "\n",
    "''' Prediction layer '''\n",
    "prediction = tf.keras.layers.Dense(\n",
    "    units=vocab_size,\n",
    "    name=\"Dense_Layer\"\n",
    ")(gru_output)\n",
    "\n",
    "model = tf.keras.Model(inputs=x, outputs=prediction)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "058a7f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer='adam', loss=loss)\n",
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_dir/stateful/v3_fit'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "13bcba25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "172/172 [==============================] - 5s 24ms/step - loss: 2.7029\n",
      "Epoch 2/20\n",
      "172/172 [==============================] - 4s 25ms/step - loss: 2.0034\n",
      "Epoch 3/20\n",
      "172/172 [==============================] - 4s 24ms/step - loss: 1.7453\n",
      "Epoch 4/20\n",
      "172/172 [==============================] - 4s 25ms/step - loss: 1.5867\n",
      "Epoch 5/20\n",
      "172/172 [==============================] - 4s 25ms/step - loss: 1.4886\n",
      "Epoch 6/20\n",
      "172/172 [==============================] - 4s 25ms/step - loss: 1.4218\n",
      "Epoch 7/20\n",
      "172/172 [==============================] - 4s 25ms/step - loss: 1.3739\n",
      "Epoch 8/20\n",
      "172/172 [==============================] - 4s 25ms/step - loss: 1.3328\n",
      "Epoch 9/20\n",
      "172/172 [==============================] - 4s 25ms/step - loss: 1.2956\n",
      "Epoch 10/20\n",
      "172/172 [==============================] - 4s 25ms/step - loss: 1.2633\n",
      "Epoch 11/20\n",
      "172/172 [==============================] - 4s 25ms/step - loss: 1.2306\n",
      "Epoch 12/20\n",
      "172/172 [==============================] - 4s 25ms/step - loss: 1.1987\n",
      "Epoch 13/20\n",
      "172/172 [==============================] - 5s 26ms/step - loss: 1.1659\n",
      "Epoch 14/20\n",
      "172/172 [==============================] - 5s 27ms/step - loss: 1.1329\n",
      "Epoch 15/20\n",
      "172/172 [==============================] - 5s 27ms/step - loss: 1.0976\n",
      "Epoch 16/20\n",
      "172/172 [==============================] - 5s 28ms/step - loss: 1.0613\n",
      "Epoch 17/20\n",
      "172/172 [==============================] - 5s 29ms/step - loss: 1.0262\n",
      "Epoch 18/20\n",
      "172/172 [==============================] - 5s 29ms/step - loss: 0.9902\n",
      "Epoch 19/20\n",
      "172/172 [==============================] - 5s 29ms/step - loss: 0.9539\n",
      "Epoch 20/20\n",
      "172/172 [==============================] - 5s 30ms/step - loss: 0.9201\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "history = model.fit(\n",
    "    dataset, \n",
    "    epochs=EPOCHS, \n",
    "    callbacks=[checkpoint_callback],\n",
    "    workers=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "e4f9f81d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x1ffe61dc100>"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model_stateful.load_weights('./training_dir/stateful/v3_fit/ckpt_19')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "636116c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMEO:\n",
      "\n",
      "Provost:\n",
      "\n",
      "ISABELLA:\n",
      "Yes, I will not.\n",
      "\n",
      "PETRUCHIO:\n",
      "Well, and say you?\n",
      "\n",
      "ANGELO:\n",
      "What is't, widdon, Saint George, I would be unknown;\n",
      "For maidy, yet this would be myself,\n",
      "With fain and age: command an alute good,\n",
      "And, from the thing we spake of sovereign.\n",
      "\n",
      "KATHARINA:\n",
      "I dare not say mehee o jest or it:\n",
      "That I wear nothing\n",
      "Shall vie; sweet Isabel,\n",
      "I will not so unto my brother\n",
      "And most gue dishonourebour than a man.\n",
      "\n",
      "MIRANDA:\n",
      "How goes it to?\n",
      "\n",
      "TRANIO:\n",
      "You\n",
      "go to physic then person belock,\n",
      "As to speak to the pedvant: speak me, Signior Lucentio horse;\n",
      "For 'tis acquainted with!\n",
      "What, shall we go? then wagars we?\n",
      "Shall we wear her in her eyes,\n",
      "Be strange: there shall speak before you do: I had mine arrive her\n",
      "To take this mere favou loudest, as honest\n",
      "Than Seeming of Signior Bracks now in Padua for thy life\n",
      "Persuadesturn'd to your holy love.\n",
      "\n",
      "SEBASTIAN:\n",
      "O Arily, you are telf?\n",
      "\n",
      "BENVOLIO:\n",
      "Tell me, Harry, were it become this.\n",
      "\n",
      "PETRUCHIO:\n",
      "Nay, that Parland where it is: I pray you, be your bidain I w\n"
     ]
    }
   ],
   "source": [
    "next_char = tf.constant('ROMEO:')\n",
    "result = []\n",
    "result.append([next_char])\n",
    "\n",
    "for n in range(1000):\n",
    "    next_char = one_step_prediction_stateful(new_model_stateful, next_char)\n",
    "    result.append([next_char])\n",
    "res = tf.strings.join(result)\n",
    "print(res.numpy()[0].decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2a185c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
